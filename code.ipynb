{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Classification using Fingerprints\n",
    "I will first start with converting those images into pixels value to extract the features from the fingerprints. Then I will split the data into training, testing and validation sets. Now let’s start with importing the libraries we need for this task and performing some steps of data preparation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_label(img_path,train = True):\n",
    "  filename, _ = os.path.splitext(os.path.basename(img_path))\n",
    "\n",
    "  subject_id, etc = filename.split('__')\n",
    "  \n",
    "  if train:\n",
    "      gender, lr, finger, _, _ = etc.split('_')\n",
    "  else:\n",
    "      gender, lr, finger, _ = etc.split('_')\n",
    "  \n",
    "  gender = 0 if gender == 'M' else 1\n",
    "  lr = 0 if lr == 'Left' else 1\n",
    "\n",
    "  if finger == 'thumb':\n",
    "      finger = 0\n",
    "  elif finger == 'index':\n",
    "      finger = 1\n",
    "  elif finger == 'middle':\n",
    "      finger = 2\n",
    "  elif finger == 'ring':\n",
    "      finger = 3\n",
    "  elif finger == 'little':\n",
    "      finger = 4\n",
    "  return np.array([gender], dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our next step is to load the image path to the function we created to iterate all over the images to find labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img_size = 96\n",
    "\n",
    "def loading_data(path,train):\n",
    "    print(\"loading data from: \",path)\n",
    "    data = []\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            img_resize = cv2.resize(img_array, (img_size, img_size))\n",
    "            label = extract_label(os.path.join(path, img),train)\n",
    "            data.append([label[0], img_resize ])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the next step is to assign various directories or folders to use the loading data function on all the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Real_path = \"../input/aman/web/Real\"\n",
    "Easy_path = \"../input/aman/web/Altered-Easy\"\n",
    "Medium_path = \"../input/aman/web/Altered-Medium\"\n",
    "Hard_path = \"../input/aman/web/Altered-Hard\"\n",
    "\n",
    "\n",
    "Easy_data = loading_data(Easy_path, train = True)\n",
    "Medium_data = loading_data(Medium_path, train = True)\n",
    "Hard_data = loading_data(Hard_path, train = True)\n",
    "test = loading_data(Real_path, train = False)\n",
    "\n",
    "data = np.concatenate([Easy_data, Medium_data, Hard_data], axis=0)\n",
    "\n",
    "del Easy_data, Medium_data, Hard_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s randomize the data and test the arrays to see what our data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(data)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will split the image arrays and image labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img, labels = [], []\n",
    "for label, feature in data:\n",
    "    labels.append(label)\n",
    "    img.append(feature)\n",
    "train_data = np.array(img).reshape(-1, img_size, img_size, 1)\n",
    "train_data = train_data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building CNN for Gender Classification Model\n",
    "Now, here I will build a Convolutional Neural Network for Gender classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = Sequential([\n",
    "                    Conv2D(32, 3, padding='same', activation='relu',kernel_initializer='he_uniform', input_shape = [96, 96, 1]),\n",
    "                    MaxPooling2D(2),\n",
    "                    Conv2D(32, 3, padding='same', kernel_initializer='he_uniform', activation='relu'),\n",
    "                    MaxPooling2D(2),\n",
    "                    Flatten(),\n",
    "                    Dense(128, kernel_initializer='he_uniform',activation = 'relu'),\n",
    "                    Dense(2, activation = 'softmax'),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will compile the model using Adam optimizers, with a learning rate of 10%, and to prevent our CNN model from overfitting, I will be using the early_stopping_call method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizers.Adam(1e-3), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data, train_labels, batch_size = 128, epochs = 30, \n",
    "          validation_split = 0.2, callbacks = [early_stopping_cb], verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have successfully trained our CNN for Gender Classification Model with a training accuracy of 99 per cent and Validation accuracy of 98 per cent. Now, let’s have a look at the performance of our Gender Classification Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we split the training images into image labels and image arrays while training our model, we need to repeat the same process on the test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = [], []\n",
    "\n",
    "for label, feature in test:\n",
    "    test_images.append(feature)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "test_images = np.array(test_images).reshape(-1, img_size, img_size, 1)\n",
    "test_images = test_images / 255.0\n",
    "del test\n",
    "test_labels  = to_categorical(test_labels, num_classes = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s evaluate the performance of our CNN model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
